{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbdbc75",
   "metadata": {
    "id": "1fbdbc75"
   },
   "source": [
    "![logo](https://github.com/HelmholtzAI-Consultants-Munich/DL-lecture-tutorials/blob/main/figures/1128-191-max.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a619e",
   "metadata": {
    "id": "040a619e"
   },
   "source": [
    "# Image classification with Deep Learning \n",
    "---\n",
    "\n",
    "In the previous tutorial we performed binary classification, and we descovered that, even if it is not perfect, the Teachable Machine is able to recognize Covid and Non-Covid cases; a difficult task for a technician to perform and impossible for people with no medical background to undertake.\n",
    "\n",
    "Now let's have a closer look at a Neural Network (NN) over a different dataset for multi-class classification. In this tutorial, you will directly see a coding example of a deep NN, in order to see what hides behind an interface like the one we used in the first section of this lecture.\n",
    "\n",
    "In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own on the browser.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HelmholtzAI-Consultants-Munich/DL-lecture-tutorials/blob/translatum_2023/notebooks/DL_Classification_tutorial.ipynb)\n",
    "\n",
    "In this tutorial you will only have to execute the cell, look at the outputs, and discuss them with your group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb28b2",
   "metadata": {
    "id": "a1cb28b2"
   },
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "#### ðŸ’¡ Key concepts\n",
    "Deep Learning (DL) is a subset of Machine Learning (ML) that uses Artificial Neural Networks (ANN or simply NN) to mimic the learning process of the human brain.\n",
    "\n",
    "The structure of NN is made up of vertical stucked components called **layers**. There are Three types of layers:\n",
    "- **Input Layer:** this is the first layer of the NN, and it accepts the data and passes it to the rest of the network\n",
    "- **Hidden Layer:** can be one or more, and this kind of layer is the one responsible for the excellent performance and complexity of NNs. They can perform a series of functions and feature creation that allows to solve really highly non-linear problems\n",
    "- **Output Layers:** this is the last layer, and it holds the results or output of the problem\n",
    "\n",
    "To visualize and explore the different layers, you can use the Google website TensorFlow Playground.\n",
    "\n",
    "![ANN](https://github.com/HelmholtzAI-Consultants-Munich/DL-lecture-tutorials/blob/translatum_2023/figures/ANN.png?raw=true)\n",
    "\n",
    "We prepared an extra tutorial that you can find in the Homeowrk section and that you can do at home."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ab961d",
   "metadata": {
    "id": "00ab961d"
   },
   "source": [
    "### Setup the environment\n",
    "If you already did the \"Teachable Machine\" tutorial or you are not running the notebook in Colab, go directly to Import and Install section. Otherwise, run and follow the steps in the upcoming cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37baef46",
   "metadata": {
    "cellView": "form",
    "id": "37baef46"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Step 1. Run this cell to connect your Google Drive to Colab and install packages\n",
    "#@markdown * Click on the URL.\n",
    "#@markdown * Sign in your Google Account.\n",
    "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
    "#mounts user's Google Drive to Google Colab.\n",
    "#@markdown At this point, a folder has been created in your Drive and you can navigate it through the lefthand panel in Colab, you might also have received an email that informs you about the access on your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive\n",
    "!git clone --branch translatum_2023 https://github.com/HelmholtzAI-Consultants-Munich/DL-lecture-tutorials.git\n",
    "%cd /content/drive/MyDrive/DL-lecture-tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277648b",
   "metadata": {
    "id": "e277648b"
   },
   "source": [
    "### Import and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32477f",
   "metadata": {
    "id": "ea32477f"
   },
   "outputs": [],
   "source": [
    "!pip install alive_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fcf17",
   "metadata": {
    "id": "9a8fcf17"
   },
   "outputs": [],
   "source": [
    "# Run this cell to import the main packages we will use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sklearn\n",
    "import random\n",
    "random.seed(1)\n",
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "import plotly.graph_objects as go\n",
    "import scipy.ndimage\n",
    "from skimage import io \n",
    "from alive_progress import alive_bar\n",
    "from check_file import *\n",
    "from utils import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfe01d",
   "metadata": {
    "id": "dddfe01d"
   },
   "source": [
    "### Dataset \n",
    "\n",
    "The [MedNIST](https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb), was gathered from several sets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset and is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic).\n",
    "\n",
    "The original dataset counts more than 50k images, which we reduced for the purposes of this tutorial. Run the following commands to download the dataset to your Drive and unzip it. Note that this step might take a few minutes.\n",
    "\n",
    "In this tutorial, we will use the MedNIST dataset in order to predict whether the image belongs to one of the six possible classes. Therefore, this is a classic example of **multi-class classification**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cb8e4",
   "metadata": {
    "id": "2a9cb8e4"
   },
   "outputs": [],
   "source": [
    "# Define path\n",
    "main_path = '/content/drive/MyDrive/DL-lecture-tutorials/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288aacf",
   "metadata": {
    "id": "7288aacf"
   },
   "outputs": [],
   "source": [
    "!curl -L https://www.dropbox.com/s/wrbfk4o63f3cn5k/MedNIST_0.5.zip?dl=1 > /content/drive/MyDrive/DL-lecture-tutorials/MedNIST_0.5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805864b1",
   "metadata": {
    "id": "805864b1"
   },
   "outputs": [],
   "source": [
    "shutil.unpack_archive(main_path + 'MedNIST_0.5.zip', main_path)\n",
    "shutil.rmtree(main_path + '__MACOSX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791e6c9",
   "metadata": {
    "id": "6791e6c9"
   },
   "source": [
    "Now let's have a look at the data.\n",
    "First, we need to save all the image names in a dataframe (df), i.e. a table, to have direct and quick access to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9d0a8",
   "metadata": {
    "id": "a6e9d0a8"
   },
   "outputs": [],
   "source": [
    "df, mp = get_MedNIST_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f59be",
   "metadata": {
    "id": "da4f59be"
   },
   "source": [
    "Now, let's see how many classes we have, their names, and labels. And also have a look at how a dataframe looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad177b",
   "metadata": {
    "id": "a5ad177b"
   },
   "outputs": [],
   "source": [
    "print(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99a529",
   "metadata": {
    "id": "1d99a529"
   },
   "outputs": [],
   "source": [
    "from google.colab import data_table\n",
    "data_table.enable_dataframe_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf7847",
   "metadata": {
    "id": "48bf7847"
   },
   "outputs": [],
   "source": [
    "df_explore = df.rename(columns={0: 'filename',\n",
    "                                1: 'class label',\n",
    "                                2: 'class name'})\n",
    "df_explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b40bce",
   "metadata": {
    "id": "61b40bce"
   },
   "source": [
    "Before we start building our classification model, run the next cell and take some time to analyze the images, and try to anticipate how the network will behave.\n",
    "\n",
    "Which classes do you expect will be harder to classify and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acc2b3",
   "metadata": {
    "id": "c3acc2b3"
   },
   "outputs": [],
   "source": [
    "plt.subplots(4, 4, figsize=(8, 8))\n",
    "random.seed(6) \n",
    "for i, k in enumerate(random.sample(range(len(df)), 16)):\n",
    "    im = PIL.Image.open(main_path + \"MedNIST_0.5/\" + df[0].iloc[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.xlabel(df[2].iloc[k])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf38eb",
   "metadata": {
    "id": "7adf38eb"
   },
   "source": [
    "### Define the structure of the Convolutional Neural Network (CNN)\n",
    "\n",
    "#### ðŸ’¡ Key concepts\n",
    "\n",
    "The network we build is formed by several hidden layers, as shown in the image ([Image credit](https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)).\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/HelmholtzAI-Consultants-Munich/DL-lecture-tutorials/blob/main/figures/cnn.png?raw=true\" width=\"500\" height=\"300\"/>\n",
    "</div>\n",
    "\n",
    "The explanation of the layers is in the extra material session at the end of this notebook. Now we only focus on the layer that  gives the name to the whole architecture.\n",
    "\n",
    "**Convolutional layer**: convolution is a mathematical word for what is essentially a moving window or filter across the image being studied. As the filter slides over the images, the dot products between the pixel values and the filter are computed, creating the so-called convolved feature map (see image below - [credit](https://media4.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e477z2u4ge19e34frejcm5q6o228fiyohcg0viafep7&rid=giphy.gif&ct=g)).\n",
    "<div>\n",
    "<img src=\"https://media4.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e477z2u4ge19e34frejcm5q6o228fiyohcg0viafep7&rid=giphy.gif&ct=g\" width=\"300\" height=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc47814",
   "metadata": {},
   "source": [
    "### Define the structure of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79038f",
   "metadata": {
    "id": "9e79038f"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=(3,3))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3)) \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lin1 = nn.Linear(3136, 64)\n",
    "        self.lin2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x) \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df03bc",
   "metadata": {
    "id": "55df03bc"
   },
   "source": [
    "### Set up the parameters\n",
    "\n",
    "We define the input/output and the hyperparameters which, unlike the parameters that describe the model itself, characterize the learning process. In particular, we define:\n",
    "\n",
    "- in_channels: number of input channels\n",
    "- num_classes = number of possible output., i.e. the class that can be predicted (in the case of the Covid dataset the number of classes is 2; in this case, the classes present in the dataset are 6)\n",
    "- lr = learning rate is the step size during the training process that determines the speed and how well the model trains.\n",
    "- batch_size = number of samples processed before the model is updated, it's often set as a power of 2.\n",
    "- num_epochs = number of iterations over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b3604",
   "metadata": {
    "id": "a79b3604"
   },
   "outputs": [],
   "source": [
    "# Set device in case it is possible to access a GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of input and output\n",
    "in_channels = 1\n",
    "num_classes = 6\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899cc38",
   "metadata": {
    "id": "6899cc38"
   },
   "source": [
    "### Train-test split\n",
    "\n",
    "No matter if we are dealing with classification or regression problems, a crucial aspect of determining if the results are meaningful or not is the evaluation of the performance of our model. \n",
    "\n",
    "The train-test split is a technique for evaluating the performance of a machine learning algorithm that can use any supervised learning method.\n",
    "\n",
    "The goal is to divide the dataset into two sub-sets:\n",
    "\n",
    "- **Train set**: the sample of data used to fit the model.\n",
    "- **Test set**: the sample of data, unseen during the training, used to evaluate the fit machine learning model.\n",
    "\n",
    "It is essential to point out that the evaluation must be made on data that are not visible to the network during the training. In other words, the objective is to estimate the machine learning model's performance on new data not used to train the model, i.e. the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e8324",
   "metadata": {
    "id": "911e8324"
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_train_test_dataset(df, train_ratio=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e53628",
   "metadata": {
    "id": "b9e53628"
   },
   "source": [
    "### Initializing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3b2e1",
   "metadata": {
    "id": "c2a3b2e1"
   },
   "outputs": [],
   "source": [
    "model = CNN(in_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477f609",
   "metadata": {
    "id": "0477f609"
   },
   "source": [
    "### Training\n",
    "\n",
    "The training will take a few minutes. Notice that the 'Current loss' decreases during the training phase, meaning that the network is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1f7f4",
   "metadata": {
    "id": "a2c1f7f4"
   },
   "outputs": [],
   "source": [
    "# train network\n",
    "def train(model, train_data, test_data, num_epochs):\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    loss_list = []\n",
    "    loss_test_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        with alive_bar(len(train_data), title= (f'Epoch {epoch}'), force_tty=True, bar='classic', spinner='dots_waves') as bar:\n",
    "            for batch, (data, targets, _) in enumerate(train_data):\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                #Forward\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient descent\n",
    "                optimizer.step()\n",
    "                bar()\n",
    "        print(epoch, \"Current Loss:\", loss)\n",
    "        loss_list.append(loss.detach().item())\n",
    "        loss_test_list.append(evaluate_loss(model, test_data, device))\n",
    "        \n",
    "    # Display learning curves\n",
    "    fig = go.Figure(layout=go.Layout(xaxis=dict(title=\"Epochs\"),\n",
    "                                 yaxis=dict(title=\"Loss\"),\n",
    "                                 title = 'Learning curves from train and test set'))\n",
    "\n",
    "    fig.add_scatter(marker=dict(size=7, color=\"dodgerblue\"))\n",
    "    fig.data[-1].x = [i for i in range(len(loss_list))]\n",
    "    fig.data[-1].y = loss_list\n",
    "    fig.data[-1].name = 'train loss'\n",
    "\n",
    "    fig.add_scatter(marker=dict(size=7, color=\"coral\"))\n",
    "    fig.data[-1].x = [i for i in range(len(loss_test_list))]\n",
    "    fig.data[-1].y = loss_test_list\n",
    "    fig.data[-1].name = 'test loss'\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return loss_list, loss_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d283ed9",
   "metadata": {
    "id": "2d283ed9"
   },
   "outputs": [],
   "source": [
    "loss_list, loss_test_list = train(model, train_loader, test_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e72a6a",
   "metadata": {
    "id": "29e72a6a"
   },
   "source": [
    "Looking at the learning curve produced at the end of the training, the network seems to perform pretty well, let's have a look also at the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bf1da",
   "metadata": {
    "id": "5b8bf1da"
   },
   "outputs": [],
   "source": [
    "# Compute accuracy  \n",
    "print('Train set:')\n",
    "list_of_train_incorrect_preds, list_of_train_preds = evaluate_score(model, train_loader, device)\n",
    "print('Test set:')\n",
    "list_of_test_incorrect_preds, list_of_test_preds = evaluate_score(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d338ae",
   "metadata": {
    "id": "72d338ae"
   },
   "source": [
    "The global accuracy looks pretty high, but let's look at the errors the network is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd6df6",
   "metadata": {
    "id": "68bd6df6"
   },
   "source": [
    "### Showcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e0fa5",
   "metadata": {
    "id": "893e0fa5"
   },
   "outputs": [],
   "source": [
    "mislabeled_image = main_path + 'MedNIST_0.5/' + list_of_test_incorrect_preds[2][0]\n",
    "plt.figure()\n",
    "im = PIL.Image.open(mislabeled_image)\n",
    "plt.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Ground Truth: ', get_key(mp, list_of_test_incorrect_preds[2][1]), '- class', list_of_test_incorrect_preds[2][1])\n",
    "print('Predicted class: ', get_key(mp, list_of_test_incorrect_preds[2][2]), '- class', list_of_test_incorrect_preds[2][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843aea25",
   "metadata": {
    "id": "843aea25"
   },
   "source": [
    "The previous cell shows a mislabeled class, probably you would expect the network to be wrong for this class.\n",
    "Let's have a look at other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debbd42",
   "metadata": {
    "id": "4debbd42"
   },
   "outputs": [],
   "source": [
    "plt.subplots(2, 3, figsize=(10, 10))\n",
    "for i, k in enumerate(random.sample(range(len(list_of_test_incorrect_preds)), 6)):\n",
    "    im = PIL.Image.open(main_path + 'MedNIST_0.5/' + list_of_test_incorrect_preds[k][0])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.xlabel({'GT: ': get_key(mp, list_of_test_incorrect_preds[k][1]),\n",
    "                'Pred: ': get_key(mp, list_of_test_incorrect_preds[k][2])})\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddfff1",
   "metadata": {
    "id": "4fddfff1"
   },
   "source": [
    "It seems that several times the network predicts a 'Chest' even though it is clearly not the case. To investigate more the kind of errors the network is doing, plot the confusion matrix and look at the accuracy per each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35823a16",
   "metadata": {
    "id": "35823a16"
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75e4f2",
   "metadata": {
    "id": "4d75e4f2"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix([v[0] for v in list_of_test_preds],[v[1] for v in list_of_test_preds])\n",
    "display_labels = list(mp.keys())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db3995",
   "metadata": {
    "id": "55db3995"
   },
   "outputs": [],
   "source": [
    "# Accuracy per class\n",
    "for x, acc in enumerate(cm.diagonal()/cm.sum(axis=1)):\n",
    "    print(get_key(mp, x), ' - ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d16a2",
   "metadata": {
    "id": "2c7d16a2"
   },
   "source": [
    "ðŸ¤” **Discuss with your team** the possible reason why we only have such poor accuracy in certain classes.\n",
    "\n",
    "If you want you can also go up to the dataframe we printed at the beginning of this part of the tutorial, and explore the dataset more in detail, clicking on the filter button on the up-right side.\n",
    "\n",
    "In case you need a suggestion to understand why the accuracy is so low in certain classes, run the hint cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c1c10",
   "metadata": {
    "id": "882c1c10"
   },
   "outputs": [],
   "source": [
    "# Run this cell if you want a hint otherwise execute the next cells\n",
    "hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92757ba2",
   "metadata": {
    "id": "92757ba2"
   },
   "outputs": [],
   "source": [
    "# Run this cell to check your answer\n",
    "check_MedNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e87b0c",
   "metadata": {
    "id": "11e87b0c"
   },
   "source": [
    "### Training on the full dataset\n",
    "\n",
    "Now that we discovered that the dataset we used was biased, let's train the model over the well-balanced dataset (same number of samples for each class) and look at the results. We will need to repeat some of the previous steps on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7da8b",
   "metadata": {
    "id": "daf7da8b"
   },
   "outputs": [],
   "source": [
    "# Dataframe creation \n",
    "df_complete, _ = get_MedNIST_dataframe(percentage_to_treat=[1., 1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4378398",
   "metadata": {
    "id": "b4378398"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_loader_complete, test_loader_complete = create_train_test_dataset(df_complete, train_ratio=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877ce0f",
   "metadata": {
    "id": "b877ce0f"
   },
   "outputs": [],
   "source": [
    "#Initialization\n",
    "model = CNN(in_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd966d5d",
   "metadata": {
    "id": "fd966d5d"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "loss_list_complete, loss_test_list_complete = train(model, train_loader_complete, test_loader_complete, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbea68",
   "metadata": {
    "id": "e4dbea68"
   },
   "outputs": [],
   "source": [
    "print('Train set:')\n",
    "list_of_train_incorrect_preds_complete, list_of_train_preds_complete = evaluate_score(model, train_loader_complete, device)\n",
    "print('Test set:')\n",
    "list_of_test_incorrect_preds_complete,  list_of_test_preds_complete = evaluate_score(model, test_loader_complete, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470c8b4",
   "metadata": {
    "id": "1470c8b4"
   },
   "outputs": [],
   "source": [
    "cm_complete = confusion_matrix([v[0] for v in list_of_test_preds_complete],[v[1] for v in list_of_test_preds_complete])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_complete, display_labels=display_labels)\n",
    "disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181badc",
   "metadata": {
    "id": "0181badc"
   },
   "outputs": [],
   "source": [
    "# Accuracy per class\n",
    "for x, acc in enumerate(cm_complete.diagonal()/cm_complete.sum(axis=1)):\n",
    "    print(get_key(mp, x), ' - ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8edc9",
   "metadata": {
    "id": "c8c8edc9"
   },
   "source": [
    "We can conclude that not only the global accuracy is improved, but also that every single class has indicatively the same accuracy value, meaning that the network is properly learning to classify images, without sub-representing any class.\n",
    "\n",
    "The goal of this tutorial was to show the difference between an imbalanced and a well-balanced dataset, most of the time it won't be possible to add more data like we did today, but there are techniques that can be used to treat an imbalanced dataset (i.e. use weighted loss functions or resample the dataset). The most important thing is to be aware of the existence of this phenomenon in order to find the best way to deal with it and avoid missing important pieces of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ec84c",
   "metadata": {
    "id": "449ec84c"
   },
   "source": [
    "### Test on a different image\n",
    "\n",
    "Finally, let's see now how our model behaves when we feed it with a completely new, different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87017f",
   "metadata": {
    "id": "7f87017f"
   },
   "outputs": [],
   "source": [
    "# Read the new image and rezise it\n",
    "single_image = PIL.Image.open(main_path + 'image_number.jpg')\n",
    "resized_image = scipy.ndimage.zoom(single_image, 2.3, order=1)\n",
    "plt.imshow(resized_image, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45343a9",
   "metadata": {
    "id": "f45343a9"
   },
   "outputs": [],
   "source": [
    "# Transoform the image before give it to the model\n",
    "transform = transforms.ToTensor()\n",
    "resized_image.reshape((1, 64, 64))\n",
    "input_image = transform(resized_image).to(device=device)\n",
    "input_image = input_image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d0263",
   "metadata": {
    "id": "199d0263"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the new image\n",
    "model.eval()              # turn the model to evaluate mode\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = model(input_image).argmax()   #gets the prediction for the image's class\n",
    "    \n",
    "print('Prediceted class:', get_key(mp, class_index.item()), '- class label: ', class_index.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a959bc2",
   "metadata": {
    "id": "3a959bc2"
   },
   "source": [
    "As you can see the network is unable to recognize that the image does not belong to any of the classes. Even if the image is not related to the dataset that we used for the training, the model always makes a prediction!\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations! You completed this tutorial!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96892335",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "To better understand the structure of a NN, open the ([Tensorflow Playground Tutorial](https://github.com/HelmholtzAI-Consultants-Munich/DL-lecture-tutorials/blob/translatum_2023/notebooks/Tensorflow_playground_tutorial.ipynb)). You can follow it on your own, performing the task and getting automatic feedback and answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dde3f",
   "metadata": {
    "id": "4d8dde3f"
   },
   "source": [
    "### Extra material\n",
    "\n",
    "Here you can find other details about the network architecture, in particular the explanation of the other layers.\n",
    "\n",
    "**Max pooling layer**: It is another sliding window type technique, but instead of applying weights as in the convolution, it applies the max function over the contents of the window. A pooling layer is a way to subsample an input feature map or output from the convolutional layer that has already extracted salient features from an image, this is also called downsampling.\n",
    "\n",
    "**Dropout layer**: dropout removes a percentage of the neuron connections - helping to prevent overfitting by reducing the feature space for convolutional and, especially, dense layers.\n",
    "\n",
    "**Linear layer**: The linear layer is used in the final stages of the neural network. It is also called a fully connected layer. This layer helps in changing the dimensionality of the output from the preceding layer so that the model can easily define the relationship between the values of the data and give the final probabilities for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe38ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
